{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a395afb9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üåé Air Quality Forecast App ‚Äì Los Angeles\n",
    "# Integrating WAQI (Real-time) & Meteomatics (Historical + 24hr API Forecast)\n",
    "# Using a 24hr SARIMA model for forecasting\n",
    "# ============================================\n",
    "\n",
    "# Ensure necessary libraries are installed\n",
    "# !pip install requests pandas plotly scikit-learn statsmodels\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings from statsmodels to keep the output clean\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==============================\n",
    "# üîê User Config\n",
    "# ==============================\n",
    "CITY = \"Los Angeles\"\n",
    "LAT, LON = 34.0522, -118.2437  # Coordinates for Los Angeles\n",
    "\n",
    "# --- API TOKENS & CREDENTIALS ---\n",
    "# Get a free token from https://aqicn.org/data-platform/token/\n",
    "AQICN_API_TOKEN = \"adab0250428e88549d94621afbdaa2c1c36d00c5\"\n",
    "\n",
    "# Enter your Meteomatics API credentials here\n",
    "METEO_USER = \"menon_prithvishankar\"\n",
    "METEO_PASS = \"Q6bRXp5GWf1mLoLa7Jz1\"\n",
    "\n",
    "# ==============================\n",
    "# 1Ô∏è‚É£ Fetch Real-time Data (Air Quality Open Data Platform)\n",
    "# ==============================\n",
    "def get_waqi_data(lat, lon, token):\n",
    "    \"\"\"\n",
    "    Fetches the latest air quality data from the World Air Quality Index project.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.waqi.info/feed/geo:{lat};{lon}/?token={token}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if data.get(\"status\") == \"ok\":\n",
    "            return data[\"data\"].get(\"iaqi\", {})\n",
    "        else:\n",
    "            print(f\"‚ùå WAQI API returned an error: {data.get('data')}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Error fetching data from WAQI API: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==============================\n",
    "# 2Ô∏è‚É£ Fetch Historical & API Forecast Data (Meteomatics)\n",
    "# ==============================\n",
    "def get_air_quality_data_meteomatics(lat, lon, pollutants, username, password):\n",
    "    \"\"\"\n",
    "    Fetches historical (90 days) and forecast (24 hours) air quality data\n",
    "    from the Meteomatics API using Basic Authentication.\n",
    "    \"\"\"\n",
    "    # Mapping from WAQI names to Meteomatics parameter names\n",
    "    pollutant_mapping = {\n",
    "        'pm25': 'pm2p5:ugm3',\n",
    "        'pm10': 'pm10:ugm3',\n",
    "        'o3': 'o3:ugm3',\n",
    "        'no2': 'no2:ugm3',\n",
    "        'so2': 'so2:ugm3',\n",
    "        'co': 'co:ugm3'\n",
    "    }\n",
    "    # Create a reverse mapping to rename columns back to the simple format\n",
    "    reverse_mapping = {v: k for k, v in pollutant_mapping.items()}\n",
    "\n",
    "    # Filter for pollutants available in Meteomatics and build the parameter string\n",
    "    meteomatics_params = [pollutant_mapping[p] for p in pollutants if p in pollutant_mapping]\n",
    "    if not meteomatics_params:\n",
    "        print(\"‚ùå None of the available real-time pollutants can be mapped for Meteomatics data.\")\n",
    "        return pd.DataFrame()\n",
    "    params_str = \",\".join(meteomatics_params)\n",
    "\n",
    "    # Define the time range (90 days past to 24 hours future, hourly interval)\n",
    "    end_time = dt.datetime.utcnow() + dt.timedelta(hours=24) # <-- CHANGED\n",
    "    start_time = dt.datetime.utcnow() - dt.timedelta(days=90)\n",
    "    time_str = f\"{start_time.isoformat(timespec='seconds')}Z--{end_time.isoformat(timespec='seconds')}Z:PT1H\"\n",
    "\n",
    "    # Location string\n",
    "    location_str = f\"{lat},{lon}\"\n",
    "\n",
    "    # Construct the final API URL\n",
    "    url = f\"https://api.meteomatics.com/{time_str}/{params_str}/{location_str}/json\"\n",
    "    print(\"Querying Meteomatics API for 24-hour forecast...\")\n",
    "\n",
    "    try:\n",
    "        # Make the request with authentication\n",
    "        response = requests.get(url, auth=(username, password))\n",
    "        response.raise_for_status()  # This will raise an error for bad responses (4xx or 5xx)\n",
    "        data = response.json()\n",
    "\n",
    "        if data.get('status') != 'OK' or not data.get('data'):\n",
    "            print(f\"‚ùå Meteomatics API returned an error: {data.get('message')}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Parse the Meteomatics JSON structure into a pandas DataFrame\n",
    "        all_data = {}\n",
    "        for param_data in data['data']:\n",
    "            param_name = param_data['parameter']\n",
    "            dates = param_data['coordinates'][0]['dates']\n",
    "            values = [d['value'] for d in dates]\n",
    "            all_data[param_name] = values\n",
    "        \n",
    "        df = pd.DataFrame(all_data)\n",
    "        # The 'date' is the same for all parameters, so we can take it from the first one\n",
    "        df['datetime'] = [d['date'] for d in data['data'][0]['coordinates'][0]['dates']]\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'], utc=True)\n",
    "\n",
    "        # Rename columns to the simple format for consistency (e.g., 'pm25')\n",
    "        df.rename(columns=reverse_mapping, inplace=True)\n",
    "        \n",
    "        print(f\"‚úÖ Fetched historical & API forecast data from Meteomatics. Size: {df.shape}\")\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"‚ùå HTTP Error fetching from Meteomatics: {e.response.status_code} {e.response.text}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An unexpected error occurred with Meteomatics API: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 3Ô∏è‚É£ Advanced Forecast (SARIMA Model)\n",
    "# ==============================\n",
    "def forecast_pollutant_sarima(df, pollutant, hours_ahead=24):\n",
    "    \"\"\"\n",
    "    Generates a forecast for a given pollutant using a SARIMA model.\n",
    "    This should be trained ONLY on historical data.\n",
    "    \"\"\"\n",
    "    df_filtered = df.dropna(subset=[pollutant]).copy()\n",
    "    if len(df_filtered) < 50:\n",
    "        print(f\"Not enough historical data to forecast {pollutant} with SARIMA.\")\n",
    "        return None\n",
    "\n",
    "    time_series = df_filtered.set_index('datetime')[pollutant].asfreq('H')\n",
    "    order = (1, 1, 1)\n",
    "    seasonal_order = (1, 1, 1, 24)\n",
    "\n",
    "    try:\n",
    "        model = ARIMA(time_series, order=order, seasonal_order=seasonal_order)\n",
    "        model_fit = model.fit()\n",
    "        forecast = model_fit.get_forecast(steps=hours_ahead)\n",
    "        forecast_df = forecast.summary_frame()\n",
    "        future_time = [time_series.index[-1] + dt.timedelta(hours=i+1) for i in range(hours_ahead)]\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            \"datetime\": future_time,\n",
    "            f\"{pollutant}_forecast\": forecast_df['mean'].values,\n",
    "            f\"{pollutant}_lower_ci\": forecast_df['mean_ci_lower'].values,\n",
    "            f\"{pollutant}_upper_ci\": forecast_df['mean_ci_upper'].values\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå SARIMA model failed for {pollutant}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==============================\n",
    "# 4Ô∏è‚É£ Visualization (Plotly with All Data Series)\n",
    "# ==============================\n",
    "def plot_pollutant(historical_df, api_forecast_df, sarima_forecast_df, pollutant, city):\n",
    "    \"\"\"\n",
    "    Plots historical data, the Meteomatics API forecast, and our SARIMA forecast.\n",
    "    \"\"\"\n",
    "    pollutant_name = pollutant.upper()\n",
    "    title = f\"{pollutant_name} Data & 24-Hour Forecast Comparison ‚Äì {city}\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # 1. Historical Data (Solid Blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=historical_df[\"datetime\"], y=historical_df[pollutant],\n",
    "        mode='lines', name='Historical Data', line=dict(color='blue')\n",
    "    ))\n",
    "\n",
    "    # 2. API Forecast (Dashed Sky Blue)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=api_forecast_df[\"datetime\"], y=api_forecast_df[pollutant],\n",
    "        mode='lines', name='API Forecast', line=dict(color='#87CEEB', dash='dash')\n",
    "    ))\n",
    "\n",
    "    # 3. Our SARIMA Forecast (Dotted Red)\n",
    "    if sarima_forecast_df is not None:\n",
    "        forecast_col = f\"{pollutant}_forecast\"\n",
    "        lower_ci_col = f\"{pollutant}_lower_ci\"\n",
    "        upper_ci_col = f\"{pollutant}_upper_ci\"\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=sarima_forecast_df[\"datetime\"], y=sarima_forecast_df[forecast_col],\n",
    "            mode='lines', name='Our SARIMA Forecast', line=dict(color='red', dash='dot')\n",
    "        ))\n",
    "\n",
    "        # Confidence Interval for SARIMA forecast (Light Red Fill)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=pd.concat([sarima_forecast_df[\"datetime\"], sarima_forecast_df[\"datetime\"][::-1]]),\n",
    "            y=pd.concat([sarima_forecast_df[upper_ci_col], sarima_forecast_df[lower_ci_col][::-1]]),\n",
    "            fill='toself', fillcolor='rgba(255, 0, 0, 0.2)',\n",
    "            line=dict(color='rgba(255,255,255,0)'),\n",
    "            hoverinfo=\"skip\", showlegend=True, name='SARIMA 95% Confidence'\n",
    "        ))\n",
    "        \n",
    "        # Define zoom ranges\n",
    "        zoom_start = api_forecast_df[\"datetime\"].iloc[0] - dt.timedelta(hours=24) if not api_forecast_df.empty else historical_df[\"datetime\"].iloc[-1]\n",
    "        zoom_end = sarima_forecast_df[\"datetime\"].iloc[-1] + dt.timedelta(hours=1)\n",
    "        full_view_start = historical_df[\"datetime\"].min()\n",
    "        full_view_end = sarima_forecast_df[\"datetime\"].max()\n",
    "        \n",
    "    else: # Fallback if SARIMA fails\n",
    "        full_view_start = historical_df[\"datetime\"].min()\n",
    "        full_view_end = api_forecast_df[\"datetime\"].max() if not api_forecast_df.empty else historical_df[\"datetime\"].max()\n",
    "        zoom_start = api_forecast_df[\"datetime\"].iloc[0] - dt.timedelta(hours=24) if not api_forecast_df.empty else historical_df[\"datetime\"].iloc[-1]\n",
    "        zoom_end = api_forecast_df[\"datetime\"].max() if not api_forecast_df.empty else historical_df[\"datetime\"].max()\n",
    "        \n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Time (UTC)\",\n",
    "        yaxis_title=f\"{pollutant_name} (Concentration / AQI)\",\n",
    "        legend_title_text='',\n",
    "        updatemenus=[dict(\n",
    "            type=\"buttons\", direction=\"right\",\n",
    "            x=0.57, xanchor=\"left\", y=1.15, yanchor=\"top\",\n",
    "            showactive=True,\n",
    "            buttons=list([\n",
    "                dict(label=\"Full View\", method=\"relayout\",\n",
    "                     args=[{\"xaxis.range\": [full_view_start, full_view_end]}]),\n",
    "                dict(label=\"Zoom to Forecast\", method=\"relayout\",\n",
    "                     args=[{\"xaxis.range\": [zoom_start, zoom_end]}])\n",
    "            ])\n",
    "        )]\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# ==============================\n",
    "# 5Ô∏è‚É£ Health Alerts\n",
    "# ==============================\n",
    "def generate_alerts(df, pollutant, threshold):\n",
    "    \"\"\"\n",
    "    Checks if a pollutant's forecasted value exceeds a given threshold.\n",
    "    Based on our SARIMA model's forecast.\n",
    "    \"\"\"\n",
    "    pollutant_name = pollutant.upper()\n",
    "    forecast_col = f\"{pollutant}_forecast\"\n",
    "    high_values = df[df[forecast_col] > threshold]\n",
    "    if not high_values.empty:\n",
    "        max_val = high_values[forecast_col].max()\n",
    "        print(f\"üö® ALERT! Unhealthy {pollutant_name} levels predicted by SARIMA. Max forecast: {max_val:.2f} (Threshold: {threshold})\")\n",
    "    else:\n",
    "        print(f\"‚úÖ SARIMA forecasted {pollutant_name} levels are within safe limits.\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 6Ô∏è‚É£ Main Analysis Loop\n",
    "# ==============================\n",
    "real_time_aq_data = get_waqi_data(LAT, LON, AQICN_API_TOKEN)\n",
    "if real_time_aq_data:\n",
    "    print(f\"‚úÖ Real-time data fetched for {CITY}: {list(real_time_aq_data.keys())}\")\n",
    "    available_pollutants_realtime = list(real_time_aq_data.keys())\n",
    "    \n",
    "    # Fetch combined historical and forecast data from the Meteomatics API\n",
    "    combined_df = get_air_quality_data_meteomatics(\n",
    "        LAT, LON, available_pollutants_realtime, METEO_USER, METEO_PASS\n",
    "    )\n",
    "\n",
    "    if not combined_df.empty:\n",
    "        # Define the split point (current time)\n",
    "        now_utc = pd.Timestamp.utcnow()\n",
    "        historical_df = combined_df[combined_df['datetime'] <= now_utc].copy()\n",
    "        api_forecast_df = combined_df[combined_df['datetime'] > now_utc].copy()\n",
    "        \n",
    "        print(f\"Data split: {len(historical_df)} historical points, {len(api_forecast_df)} API forecast points.\")\n",
    "\n",
    "        HEALTH_THRESHOLDS = {'pm25': 35, 'pm10': 75, 'o3': 70, 'no2': 100, 'so2': 75, 'co': 9000}\n",
    "        available_pollutants = [col for col in combined_df.columns if col not in ['datetime']]\n",
    "\n",
    "        for pollutant in available_pollutants:\n",
    "            print(f\"\\n--- Analyzing {pollutant.upper()} ---\")\n",
    "\n",
    "            # 1. Generate SARIMA Forecast using ONLY historical data\n",
    "            sarima_forecast_df = forecast_pollutant_sarima(historical_df, pollutant, hours_ahead=24) # <-- CHANGED\n",
    "\n",
    "            # 2. Plot all three data series\n",
    "            plot_pollutant(historical_df, api_forecast_df, sarima_forecast_df, pollutant, CITY)\n",
    "\n",
    "            # 3. Check for Health Alerts based on our SARIMA forecast\n",
    "            if sarima_forecast_df is not None:\n",
    "                threshold = HEALTH_THRESHOLDS.get(pollutant, 150)\n",
    "                generate_alerts(sarima_forecast_df, pollutant, threshold)\n",
    "else:\n",
    "    print(\"Could not fetch real-time data to proceed with analysis.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
